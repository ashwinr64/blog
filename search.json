[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I write about tech, finance and all things I learn"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Subsampling tick data efficiently using Redis\n\n\n\n\n\n\nsoftware\n\n\n\n\n\n\n\n\n\nMay 19, 2024\n\n\nAshwin Ramesh\n\n\n\n\n\n\n\n\n\n\n\n\nHello World!\n\n\n\n\n\n\nblogging\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nChristian Wittmann\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "",
    "text": "Redis-Py"
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#introduction",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#introduction",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Introduction",
    "text": "Introduction\nIn financial markets, tick data refers to the detailed record of every trade executed on an exchange. In liquid markets, where thousands of trades occur every second, transmitting and processing this high-frequency data can be computationally intensive. Even if the data is available, retail traders do not have the resources to leverage it effectively for real-time decision-making. To address this challenge, exchanges and brokers often provide aggregated price information to their clients."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#subsampling-aggregated-price-data-for-mft-and-lft",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#subsampling-aggregated-price-data-for-mft-and-lft",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Subsampling aggregated price data for MFT and LFT",
    "text": "Subsampling aggregated price data for MFT and LFT\nFor medium frequency trading (MFT) and low frequency trading (LFT), the aggregated price data needs to be further subsampled to generate OHLC (open, high, low, close) candles. However, managing different timeframes for multiple tickers can be complex and challenging to optimize. In this blog post, we will explore an efficient approach that utilizes native Redis features, such as Redis Timeseries, Compaction and Key-Space notifications which we will cover in detail."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#why-redis",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#why-redis",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Why Redis?",
    "text": "Why Redis?\nRedis is a versatile in-memory key-value store. It can not only be used to store key-value pairs, but also has a plethora of plugins which make it capable of handling various data types and use cases. Redis can also be extended to work with relational data using Redis OM (Object Mapping).\nOther notable features of Redis include built-in support for data structures like lists, sets, sorted sets, hashes, streams and powerful pub/sub messaging capabilities. These features, combined with its in-memory storage and high performance, make Redis a go-to choice for caching."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#solution-overview",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#solution-overview",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Solution Overview",
    "text": "Solution Overview\nRedis serves as a caching layer where all the aggregated price data is cached. Since this is time-series data, we can use Redis Timeseries to efficiently store and query the data. Redis Timeseries is a simple key-value store, but the keys are timestamps and the values are price data (the value can be any relevant information). Once the data is ingested into Redis, we can create rules to subsample the data into 1m, 3m, 15m, 1h, and 1d OHLC (Open, High, Low, Close) candles. This process utilizes compaction, which automatically subsamples data based on specified aggregation functions such as sum, avg, min, max, first, last, etc.\nTo create a candle for a specific timeframe, we need to define four rules with the respective aggregation functions: open (first), high (max), low (min), and close (last). By creating these rules, we can generate candles of different timeframes and store them in the cache.\nThe next challenge is to efficiently process the candle data as soon as it is generated. A naive approach would be to use a while loop with a sleep interval equivalent to the required timeframe and query the latest data in each iteration. However, a more optimized approach is to use Keyspace notifications. With this feature, Redis sends a notification whenever any changes occur in a specified key. By subscribing to these notifications, we can efficiently query Redis only when a new candle is available, eliminating the need for constant polling."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#setup",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#setup",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Setup",
    "text": "Setup\n\nThe easiest way one can run redis is using the official redis container images available on DockerHub. Run the following command once docker is installed in your system:\n\n\n\nCode\n!docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n\n\n\nNow let us install a plugin called RedisTimeseriesManager. This plugin helps us easily create and manage several compaction rules.\n\n\n\nCode\n!pip install -qq redis-timeseries-manager\n\n\n\nNow let’s get to coding this solution. Let us first create a class that defines the compaction rules. This code is picked up from the examples of RedisTimeseriesManager.\n\n\n\nCode\nimport time, datetime, random\nfrom pytz import timezone\n\nfrom redis_timeseries_manager import RedisTimeseriesManager\n\nsettings = {\n    'host': 'localhost',\n    'port': 6379,\n    'db': 0,\n    'password': None,\n}\n\nclass MarketData(RedisTimeseriesManager):\n    _name = 'markets'\n    _lines = ['open', 'high', 'low', 'close']\n    _timeframes = {\n        'raw': {'retention_secs': 60*60*24*4}, # retention 4 days\n        '1m': {'retention_secs': 60*60*24*7, 'bucket_size_secs': 60}, # retention 7 day; timeframe 60 secs\n        '3m': {'retention_secs': 60*60*24*7, 'bucket_size_secs': 60*3}, # retention 7 day; timeframe 180 secs\n        '1h': {'retention_secs': 60*60*24*30, 'bucket_size_secs': 60*60}, # retention 1 month; timeframe 3600 secs\n        '1d': {'retention_secs': 60*60*24*365, 'bucket_size_secs': 60*60*24}, # retention 1 year; timeframe 86400 secs\n    }\n\n    #compaction rules\n    def _create_rule(self, c1:str, c2:str, line:str, timeframe_name:str, timeframe_specs:str, source_key:str, dest_key:str):\n        if line == 'open':\n            aggregation_type = 'first'\n        elif line == 'close':\n            aggregation_type = 'last'\n        elif line == 'high':\n            aggregation_type = 'max'\n        elif line == 'low':\n            aggregation_type = 'min'\n        else:\n            return\n        bucket_size_secs = timeframe_specs['bucket_size_secs']\n        self._set_rule(source_key, dest_key, aggregation_type, bucket_size_secs)\n    \n    @staticmethod\n    def print_data(data):\n        for ts, open, high, low, close, volume in data:\n            print(f\"{datetime.datetime.fromtimestamp(ts, tz=timezone('UTC')):%Y-%m-%d %H:%M:%S}, open: {open}, high: {high}, low: {low}, close: {close}, volume: {volume}\")\n\nmd = MarketData(**settings)\n\n\nThe MarketData class does the following:\n\n_name: The name of the first level of hierarchy (RedisTimeseriesManager uses two additional levels of hierarchies to manage data)\n_lines: The different types of data being stored (open, high, low, close prices).\n_timeframes: Different time intervals for storing the data (raw, 1-minute, 1-hour, 1-day) and how long to keep the data for each interval.\nThe _create_rule method is used to set up rules for automatically aggregating (compacting) the data over time, depending on the type of data (e.g., using the first price for “open”, the last price for “close”, the maximum price for “high”, and the minimum price for “low”).\nprint_data method is a utility function that takes market data and prints it out in a nice, human-readable format.\nFinally, we create an instance of the MarketData class called md, which can be used to interact with the market data stored in Redis.\n\nLet us write a function to generate dummy data:"
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#generate-dummy-data",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#generate-dummy-data",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Generate dummy data",
    "text": "Generate dummy data\n\n\nCode\ndef generate_ticks():\n    secs = 500\n    tickers = [\n        (\"crypto\", \"btcusd\", (28000, 29000)), # BTC\n        (\"crypto\", \"ethusd\", (1800, 2000)), # ETH\n        (\"stocks\", \"aapl\", (130, 140)),  # Apple\n        (\"stocks\", \"amzn\", (2300, 2400)),  # Amazon\n        (\"stocks\", \"googl\", (2200, 2300)),  # Google\n    ]\n\n    n_tickers = len(tickers)\n    sec = 0\n\n    names = [f\"{t[0]}:{t[1]}\" for t in tickers]\n    print(f\"Generating random ticks for {secs}s: {names}\")\n\n    while sec &lt; secs:\n        ts = int(time.time())\n\n        for i in range(n_tickers):\n            c1, c2, price_range = tickers[i]\n            price = random.randint(*price_range)\n\n            # print(f\"ts: {ts}, {c2.upper()}: {price}\")\n\n            md.insert(\n                data=[[ts, price, price, price, price]],\n                c1=c1,\n                c2=c2,\n                create_inplace=True,\n            )\n\n        time.sleep(1)\n        sec += 1\n# generate_ticks()\n\n\nThe generate_ticks() function utilizes the MarketData class to insert randomly generated data into Redis. Alternatively, you can use the md.insert() method to insert real-time data received from the broker into Redis. Once the data is inserted, Redis automatically handles the subsampling process. It aggregates the data into various time intervals: 1-minute, 3-minute, 1-hour, and 1-day. Each subsampled dataset has a specific expiration period:\n\n1-minute data expires after 7 days\n3-minute data expires after 7 days\n1-hour data expires after 1 month\n1-day data expires after 1 year\n\nThis automatic subsampling and expiration mechanism ensures efficient storage and retrieval of historical market data while maintaining the desired granularity for analysis and visualization purposes."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#subscribe-to-data",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#subscribe-to-data",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Subscribe to data",
    "text": "Subscribe to data\n\n\nCode\ndef handle_event(event):\n    # Handle your event here\n    print(event)\n\ndef subscribe_candle():\n    timeframes= ['1m', '3m']\n    tickers = [\n        (\"crypto\", \"btcusd\", (28000, 29000)), # BTC\n        (\"crypto\", \"ethusd\", (1800, 2000)), # ETH\n        (\"stocks\", \"aapl\", (130, 140)),  # Apple\n        (\"stocks\", \"amzn\", (2300, 2400)),  # Amazon\n        (\"stocks\", \"googl\", (2200, 2300)),  # Google\n    ]\n\n\n    r = md.client\n\n    # Enabling keyspace events (https://redis.io/docs/latest/develop/use/keyspace-notifications/#configuration)\n    r.config_set('notify-keyspace-events', 'KEA')\n\n    # Subscribe to all the tickers using pubsub\n    pubsub = r.pubsub()\n    for timeframe in timeframes:\n        for ticker in tickers:\n            market, scrip, _ = ticker\n            key = f\"__keyspace@0__:markets:{market}:{scrip}:{timeframe}:close\"\n            pubsub.psubscribe(key)\n            print(f\"Subscibed: {market}:{scrip}:{timeframe}\")\n\n    for message in pubsub.listen():\n        if message.get(\"type\") == \"pmessage\":\n            channel = message.get(\"channel\").decode() # \"__keyspace@0__:markets:stocks:amzn:1m:close\"\n            parts = channel.split(\":\")\n            market = parts[2]\n            scrip = parts[3]\n            timeframe = parts[4]\n\n            # Once we have an event use read the latest record\n            data = md.read_last_n_records(\n                c1=market,\n                c2=scrip,\n                timeframe=timeframe,\n                # minimum_timestamp=0,\n                n=1,\n            )\n\n            ohlc = data[2][0][1:]\n            ts = data[2][0][0]\n\n            event = {\n                \"ts\": ts,\n                \"market\": market,\n                \"scrip\": scrip,\n                \"ohlc\": ohlc,\n                \"tf\": timeframe\n            }\n            handle_event(event)\n\n# subscribe_candle()\n\n\nThe above method subscribe_candle() sets up keyspace notifications and uses pub/sub to subscribe to the events. Now, we can listen to these events. Whenever there is an event, we can fetch the latest candle information using md.read_last_n_records() method. Code to handle the event can be written in handle_event() callback function.\n\n\nCode\nimport threading\nt1 = threading.Thread(target=generate_ticks)\nt2 = threading.Thread(target=subscribe_candle)\n\nt1.start()\nt2.start()\nt1.join()\nt2.join()\n\n\nGenerating random ticks for 500s: ['crypto:btcusd', 'crypto:ethusd', 'stocks:aapl', 'stocks:amzn', 'stocks:googl']\nSubscibed: crypto:btcusd:1m\nSubscibed: crypto:ethusd:1m\nSubscibed: stocks:aapl:1m\nSubscibed: stocks:amzn:1m\nSubscibed: stocks:googl:1m\nSubscibed: crypto:btcusd:3m\nSubscibed: crypto:ethusd:3m\nSubscibed: stocks:aapl:3m\nSubscibed: stocks:amzn:3m\nSubscibed: stocks:googl:3m\n{'ts': 1716178800.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28344.0, 29000.0, 28011.0, 28149.0], 'tf': '1m'}\n{'ts': 1716178680.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28344.0, 29000.0, 28011.0, 28149.0], 'tf': '3m'}\n{'ts': 1716178800.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1926.0, 1989.0, 1806.0, 1963.0], 'tf': '1m'}\n{'ts': 1716178680.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1926.0, 1989.0, 1806.0, 1963.0], 'tf': '3m'}\n{'ts': 1716178800.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [131.0, 140.0, 130.0, 139.0], 'tf': '1m'}\n{'ts': 1716178680.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [131.0, 140.0, 130.0, 139.0], 'tf': '3m'}\n{'ts': 1716178800.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2392.0, 2398.0, 2300.0, 2381.0], 'tf': '1m'}\n{'ts': 1716178680.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2392.0, 2398.0, 2300.0, 2381.0], 'tf': '3m'}\n{'ts': 1716178800.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2255.0, 2299.0, 2200.0, 2218.0], 'tf': '1m'}\n{'ts': 1716178680.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2255.0, 2299.0, 2200.0, 2218.0], 'tf': '3m'}\n{'ts': 1716178860.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28273.0, 28960.0, 28034.0, 28078.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1910.0, 1997.0, 1800.0, 1954.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [135.0, 140.0, 130.0, 135.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2316.0, 2398.0, 2300.0, 2319.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2218.0, 2298.0, 2204.0, 2207.0], 'tf': '1m'}\n{'ts': 1716178920.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28209.0, 28992.0, 28013.0, 28013.0], 'tf': '1m'}\n{'ts': 1716178920.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1803.0, 1998.0, 1803.0, 1908.0], 'tf': '1m'}\n{'ts': 1716178920.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [130.0, 140.0, 130.0, 132.0], 'tf': '1m'}\n{'ts': 1716178920.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2316.0, 2399.0, 2300.0, 2336.0], 'tf': '1m'}\n{'ts': 1716178920.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2229.0, 2296.0, 2204.0, 2251.0], 'tf': '1m'}\n{'ts': 1716178980.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28299.0, 28996.0, 28000.0, 28501.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28273.0, 28996.0, 28000.0, 28501.0], 'tf': '3m'}\n{'ts': 1716178980.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1996.0, 1996.0, 1800.0, 1933.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1910.0, 1998.0, 1800.0, 1933.0], 'tf': '3m'}\n{'ts': 1716178980.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [135.0, 140.0, 130.0, 132.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [135.0, 140.0, 130.0, 132.0], 'tf': '3m'}\n{'ts': 1716178980.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2371.0, 2399.0, 2301.0, 2359.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2316.0, 2399.0, 2300.0, 2359.0], 'tf': '3m'}\n{'ts': 1716178980.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2235.0, 2296.0, 2202.0, 2263.0], 'tf': '1m'}\n{'ts': 1716178860.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2218.0, 2298.0, 2202.0, 2263.0], 'tf': '3m'}\n{'ts': 1716179040.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28452.0, 29000.0, 28015.0, 28631.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1865.0, 2000.0, 1801.0, 1986.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [137.0, 140.0, 130.0, 136.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2390.0, 2400.0, 2305.0, 2362.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2263.0, 2300.0, 2202.0, 2231.0], 'tf': '1m'}\n{'ts': 1716179100.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28845.0, 29000.0, 28007.0, 28749.0], 'tf': '1m'}\n{'ts': 1716179100.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1939.0, 1999.0, 1802.0, 1866.0], 'tf': '1m'}\n{'ts': 1716179100.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [135.0, 140.0, 130.0, 138.0], 'tf': '1m'}\n{'ts': 1716179100.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2386.0, 2398.0, 2304.0, 2307.0], 'tf': '1m'}\n{'ts': 1716179100.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2289.0, 2300.0, 2200.0, 2228.0], 'tf': '1m'}\n{'ts': 1716179160.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28441.0, 28986.0, 28001.0, 28445.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28452.0, 29000.0, 28001.0, 28445.0], 'tf': '3m'}\n{'ts': 1716179160.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1963.0, 2000.0, 1804.0, 1863.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1865.0, 2000.0, 1801.0, 1863.0], 'tf': '3m'}\n{'ts': 1716179160.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [138.0, 140.0, 130.0, 132.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [137.0, 140.0, 130.0, 132.0], 'tf': '3m'}\n{'ts': 1716179160.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2375.0, 2395.0, 2301.0, 2349.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2390.0, 2400.0, 2301.0, 2349.0], 'tf': '3m'}\n{'ts': 1716179160.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2290.0, 2299.0, 2200.0, 2277.0], 'tf': '1m'}\n{'ts': 1716179040.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2263.0, 2300.0, 2200.0, 2277.0], 'tf': '3m'}\n{'ts': 1716179220.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28219.0, 28988.0, 28040.0, 28674.0], 'tf': '1m'}\n{'ts': 1716179220.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1994.0, 1999.0, 1800.0, 1961.0], 'tf': '1m'}\n{'ts': 1716179220.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [140.0, 140.0, 130.0, 139.0], 'tf': '1m'}\n{'ts': 1716179220.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2391.0, 2397.0, 2300.0, 2393.0], 'tf': '1m'}\n{'ts': 1716179220.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2282.0, 2300.0, 2201.0, 2218.0], 'tf': '1m'}\n{'ts': 1716179280.0, 'market': 'crypto', 'scrip': 'btcusd', 'ohlc': [28604.0, 28998.0, 28001.0, 28804.0], 'tf': '1m'}\n{'ts': 1716179280.0, 'market': 'crypto', 'scrip': 'ethusd', 'ohlc': [1821.0, 1999.0, 1802.0, 1887.0], 'tf': '1m'}\n{'ts': 1716179280.0, 'market': 'stocks', 'scrip': 'aapl', 'ohlc': [137.0, 140.0, 130.0, 134.0], 'tf': '1m'}\n{'ts': 1716179280.0, 'market': 'stocks', 'scrip': 'amzn', 'ohlc': [2307.0, 2399.0, 2300.0, 2311.0], 'tf': '1m'}\n{'ts': 1716179280.0, 'market': 'stocks', 'scrip': 'googl', 'ohlc': [2277.0, 2300.0, 2202.0, 2226.0], 'tf': '1m'}\n\n\nKeyboardInterrupt: \n\n\nThe above code runs the two methods we have written in separate threads and prints out the events to console. Voila! We are receiving events for the various timeframes we have enabled."
  },
  {
    "objectID": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#conclusion",
    "href": "posts/2024-05-19-subsampling-ticks-efficiently/index.html#conclusion",
    "title": "Subsampling tick data efficiently using Redis",
    "section": "Conclusion",
    "text": "Conclusion\nIn this blog post, we have explored how to leverage the native features of Redis to create candles of different timeframes and efficiently process them using an event-driven approach. It’s important to note that enabling keyspace notifications does consume CPU resources. However, the setup process is straightforward and can be accomplished with just a few lines of code. Moreover, the scalable nature of Redis ensures that this approach is highly scalable and can handle large volumes of data.\nAlso, this is my maiden attempt at writing a technical post. I welcome feedback and suggestions. This would be valuable to improve the quality of future posts.\nThank you for reading, and I hope you found this post informative and useful in understanding how to utilize Redis for real-time candle generation and event-driven processing."
  },
  {
    "objectID": "posts/2022-10-01-hello-world/index.html",
    "href": "posts/2022-10-01-hello-world/index.html",
    "title": "Hello World!",
    "section": "",
    "text": "Hello World!"
  },
  {
    "objectID": "market_data.html",
    "href": "market_data.html",
    "title": "RedisTimeseriesManager Example: Market Data(OHLCV)",
    "section": "",
    "text": "In this example, we are going to maintain the data of some financial markets. We have chosen the cryptocurrency and irx for our example. Each market contain several instruments that we refer to them as symbols and we collect OHLCV(open, high, low, close, volume) data for each symbol.\nThe raw data is directly collected from the market with the resolution of seconds and we insert them in raw timeframe. Then we compress(downsample) the data to timeframes of 1m, 1h and 1d. As the names open, high, low, close, volume implies, we use the FIRST aggregator for open, MAX for high, MIN for low, LAST for close and the SUM aggregator for volume to compress the data and build the appropriate timeframes of data.\nWe also want to keep 1m data for just one week, 1h for one month and respectively 1d data for a year. In this Example, we use the classifier 1(c1) to identify the market(here cryptocurrency or irx) and the classifier 2(c2) for the symbols.\n\nimport time, datetime, random\nfrom pytz import timezone\n\nfrom redis_timeseries_manager import RedisTimeseriesManager\n\nsettings = {\n    'host': 'localhost',\n    'port': 6379,\n    'db': 13,\n    'password': None,\n}\n\nclass MarketData(RedisTimeseriesManager):\n    _name = 'markets'\n    _lines = ['open', 'high', 'low', 'close', 'volume']\n    _timeframes = {\n        'raw': {'retention_secs': 60*60*24*4}, # retention 4 days\n        '1m': {'retention_secs': 60*60*24*7, 'bucket_size_secs': 60}, # retention 7 day; timeframe 60 secs\n        '1h': {'retention_secs': 60*60*24*30, 'bucket_size_secs': 60*60}, # retention 1 month; timeframe 3600 secs\n        '1d': {'retention_secs': 60*60*24*365, 'bucket_size_secs': 60*60*24}, # retention 1 year; timeframe 86400 secs\n    }\n\n    #compaction rules\n    def _create_rule(self, c1:str, c2:str, line:str, timeframe_name:str, timeframe_specs:str, source_key:str, dest_key:str):\n        if line == 'open':\n            aggregation_type = 'first'\n        elif line == 'close':\n            aggregation_type = 'last'\n        elif line == 'high':\n            aggregation_type = 'max'\n        elif line == 'low':\n            aggregation_type = 'min'\n        elif line == 'volume':\n            aggregation_type = 'sum'\n        else:\n            return\n        bucket_size_secs = timeframe_specs['bucket_size_secs']\n        self._set_rule(source_key, dest_key, aggregation_type, bucket_size_secs)\n    \n    @staticmethod\n    def print_data(data):\n        for ts, open, high, low, close, volume in data:\n            print(f\"{datetime.datetime.fromtimestamp(ts, tz=timezone('UTC')):%Y-%m-%d %H:%M:%S}, open: {open}, high: {high}, low: {low}, close: {close}, volume: {volume}\")\n\n\nmd = MarketData(**settings)\n\nIn this example, we don’t create timeseries explicitly using the create() method. Instead, the series are created automatically while inserting data by turning on the create_inplace option.\n\ncrypto_btc = []\ncrypto_eth = []\nirx_usd = []\n# generating random data from 2020-01-01 to 2020-03-01; raw(seconds) resolution\nfor ts in range(1577836800, 1583020800, 60):\n    btc = (random.randint(20000, 21000), random.randint(10000000, 20000000))\n    eth = (random.randint(1500, 1600), random.randint(1000000, 2000000))\n    usd = (random.randint(30000, 35000), random.randint(1000, 2000))\n    crypto_btc.append([ts, btc[0], btc[0], btc[0], btc[0], btc[1]])\n    crypto_eth.append([ts, eth[0], eth[0], eth[0], eth[0], eth[1]])\n    irx_usd.append([ts, usd[0], usd[0], usd[0], usd[0], usd[1]])\n\n# adding data\nprint(md.insert(\n    data=crypto_btc,\n    c1='crypto',\n    c2='btc',\n    create_inplace=True,\n)[1], 'records inserted for crypto:btc:raw')\n\nprint(md.insert(\n    data=crypto_eth,\n    c1='crypto',\n    c2='eth',\n    create_inplace=True,\n)[1], 'records inserted for crypto:eth:raw')\n\nprint(md.insert(\n    data=irx_usd,\n    c1='irx',\n    c2='usd',\n    create_inplace=True,\n)[1], 'records inserted for irx:usd:raw')\n\n432000 records inserted for crypto:btc:raw\n432000 records inserted for crypto:eth:raw\n432000 records inserted for irx:usd:raw\n\n\nTaking a look at btc data in raw timeframe, printing the first 10 records. As you can see, data older than retention period is deleted:\n\ndata = md.read(\n    c1='crypto',\n    c2='btc',\n    timeframe='raw',\n)\nmd.print_data(data[1][:10])\n\n2020-02-25 23:59:00, open: 20313.0, high: 20313.0, low: 20313.0, close: 20313.0, volume: 17434667.0\n2020-02-26 00:00:00, open: 20059.0, high: 20059.0, low: 20059.0, close: 20059.0, volume: 17449903.0\n2020-02-26 00:01:00, open: 20440.0, high: 20440.0, low: 20440.0, close: 20440.0, volume: 19759404.0\n2020-02-26 00:02:00, open: 20535.0, high: 20535.0, low: 20535.0, close: 20535.0, volume: 17050135.0\n2020-02-26 00:03:00, open: 20352.0, high: 20352.0, low: 20352.0, close: 20352.0, volume: 12414002.0\n2020-02-26 00:04:00, open: 20908.0, high: 20908.0, low: 20908.0, close: 20908.0, volume: 16608832.0\n2020-02-26 00:05:00, open: 20640.0, high: 20640.0, low: 20640.0, close: 20640.0, volume: 11738248.0\n2020-02-26 00:06:00, open: 20730.0, high: 20730.0, low: 20730.0, close: 20730.0, volume: 12529980.0\n2020-02-26 00:07:00, open: 20010.0, high: 20010.0, low: 20010.0, close: 20010.0, volume: 13072315.0\n2020-02-26 00:08:00, open: 20329.0, high: 20329.0, low: 20329.0, close: 20329.0, volume: 18525989.0\n\n\nMaking sure data is properly downsampled for the 1h timeframe of btc. Just looking at last 10 records:\n\ndata = md.read_last_n_records(\n    c1='crypto',\n    c2='btc',\n    timeframe='1h',\n    minimum_timestamp=0,\n    n=10,\n)\nmd.print_data(data[2])\n\n2020-02-29 13:00:00, open: 20735.0, high: 20950.0, low: 20017.0, close: 20092.0, volume: 889585609.0\n2020-02-29 14:00:00, open: 20255.0, high: 20994.0, low: 20008.0, close: 20159.0, volume: 907397638.0\n2020-02-29 15:00:00, open: 20639.0, high: 20981.0, low: 20040.0, close: 20210.0, volume: 914919852.0\n2020-02-29 16:00:00, open: 20881.0, high: 20988.0, low: 20000.0, close: 20754.0, volume: 873184318.0\n2020-02-29 17:00:00, open: 20925.0, high: 20980.0, low: 20029.0, close: 20957.0, volume: 885453408.0\n2020-02-29 18:00:00, open: 20435.0, high: 20945.0, low: 20003.0, close: 20057.0, volume: 884260516.0\n2020-02-29 19:00:00, open: 20809.0, high: 20984.0, low: 20015.0, close: 20750.0, volume: 901757513.0\n2020-02-29 20:00:00, open: 20873.0, high: 20996.0, low: 20006.0, close: 20202.0, volume: 902661579.0\n2020-02-29 21:00:00, open: 20520.0, high: 20960.0, low: 20001.0, close: 20714.0, volume: 930434483.0\n2020-02-29 22:00:00, open: 20536.0, high: 20985.0, low: 20069.0, close: 20364.0, volume: 958616971.0\n\n\nAnd finally the 1d timeframe for btc:\n\ndata = md.read_last_n_records(\n    c1='crypto',\n    c2='btc',\n    timeframe='1d',\n    minimum_timestamp=0,\n    n=10,\n)\nmd.print_data(data[2])\n\n2020-02-19 00:00:00, open: 20731.0, high: 21000.0, low: 20000.0, close: 20115.0, volume: 21330534906.0\n2020-02-20 00:00:00, open: 20334.0, high: 21000.0, low: 20001.0, close: 20459.0, volume: 21515641617.0\n2020-02-21 00:00:00, open: 20029.0, high: 21000.0, low: 20000.0, close: 20905.0, volume: 21711650439.0\n2020-02-22 00:00:00, open: 20411.0, high: 21000.0, low: 20000.0, close: 20928.0, volume: 21446299869.0\n2020-02-23 00:00:00, open: 20085.0, high: 21000.0, low: 20001.0, close: 20492.0, volume: 21767227948.0\n2020-02-24 00:00:00, open: 20113.0, high: 21000.0, low: 20000.0, close: 20524.0, volume: 21589199638.0\n2020-02-25 00:00:00, open: 20005.0, high: 21000.0, low: 20000.0, close: 20313.0, volume: 21593589792.0\n2020-02-26 00:00:00, open: 20059.0, high: 21000.0, low: 20000.0, close: 20308.0, volume: 21449804558.0\n2020-02-27 00:00:00, open: 20248.0, high: 21000.0, low: 20000.0, close: 20430.0, volume: 21506463397.0\n2020-02-28 00:00:00, open: 20202.0, high: 21000.0, low: 20000.0, close: 20158.0, volume: 21501350295.0\n\n\nWhat about Ethereum?\n\ndata = md.read_last_n_records(\n    c1='crypto',\n    c2='eth',\n    timeframe='1d',\n    minimum_timestamp=0,\n    n=10,\n)\nmd.print_data(data[2])\n\n2020-02-19 00:00:00, open: 1596.0, high: 1600.0, low: 1500.0, close: 1556.0, volume: 2143999543.0\n2020-02-20 00:00:00, open: 1554.0, high: 1600.0, low: 1500.0, close: 1586.0, volume: 2161415271.0\n2020-02-21 00:00:00, open: 1506.0, high: 1600.0, low: 1500.0, close: 1531.0, volume: 2149807932.0\n2020-02-22 00:00:00, open: 1579.0, high: 1600.0, low: 1500.0, close: 1578.0, volume: 2154955516.0\n2020-02-23 00:00:00, open: 1585.0, high: 1600.0, low: 1500.0, close: 1581.0, volume: 2162673381.0\n2020-02-24 00:00:00, open: 1514.0, high: 1600.0, low: 1500.0, close: 1555.0, volume: 2153614376.0\n2020-02-25 00:00:00, open: 1566.0, high: 1600.0, low: 1500.0, close: 1507.0, volume: 2155428171.0\n2020-02-26 00:00:00, open: 1568.0, high: 1600.0, low: 1500.0, close: 1580.0, volume: 2160880310.0\n2020-02-27 00:00:00, open: 1545.0, high: 1600.0, low: 1500.0, close: 1598.0, volume: 2150496148.0\n2020-02-28 00:00:00, open: 1576.0, high: 1600.0, low: 1500.0, close: 1540.0, volume: 2168125300.0\n\n\nWe also had a market called irx, whats going on with it?\n\ndata = md.read_last_n_records(\n    c1='irx',\n    c2='usd',\n    timeframe='1d',\n    minimum_timestamp=0,\n    n=10,\n)\nmd.print_data(data[2])\n\n2020-02-19 00:00:00, open: 32384.0, high: 35000.0, low: 30000.0, close: 31769.0, volume: 2153204.0\n2020-02-20 00:00:00, open: 30362.0, high: 34997.0, low: 30002.0, close: 32887.0, volume: 2165782.0\n2020-02-21 00:00:00, open: 34322.0, high: 35000.0, low: 30014.0, close: 32140.0, volume: 2172368.0\n2020-02-22 00:00:00, open: 34090.0, high: 34996.0, low: 30006.0, close: 31156.0, volume: 2142013.0\n2020-02-23 00:00:00, open: 31106.0, high: 34995.0, low: 30006.0, close: 31497.0, volume: 2155531.0\n2020-02-24 00:00:00, open: 33332.0, high: 35000.0, low: 30000.0, close: 32006.0, volume: 2158651.0\n2020-02-25 00:00:00, open: 31023.0, high: 35000.0, low: 30008.0, close: 31511.0, volume: 2177522.0\n2020-02-26 00:00:00, open: 30033.0, high: 34992.0, low: 30000.0, close: 31871.0, volume: 2147087.0\n2020-02-27 00:00:00, open: 34626.0, high: 34998.0, low: 30001.0, close: 30956.0, volume: 2175925.0\n2020-02-28 00:00:00, open: 32097.0, high: 34997.0, low: 30004.0, close: 34060.0, volume: 2175474.0"
  },
  {
    "objectID": "market_data.html#other-commands",
    "href": "market_data.html#other-commands",
    "title": "RedisTimeseriesManager Example: Market Data(OHLCV)",
    "section": "Other Commands",
    "text": "Other Commands\nIn the background, several keys are created in the redis db. To inspect the list of keys, run the following command:\n\nmd.query_index(return_key_names=True)[1]\n\n['markets:crypto:btc:1d:close',\n 'markets:crypto:btc:1d:high',\n 'markets:crypto:btc:1d:low',\n 'markets:crypto:btc:1d:open',\n 'markets:crypto:btc:1d:volume',\n 'markets:crypto:btc:1h:close',\n 'markets:crypto:btc:1h:high',\n 'markets:crypto:btc:1h:low',\n 'markets:crypto:btc:1h:open',\n 'markets:crypto:btc:1h:volume',\n 'markets:crypto:btc:1m:close',\n 'markets:crypto:btc:1m:high',\n 'markets:crypto:btc:1m:low',\n 'markets:crypto:btc:1m:open',\n 'markets:crypto:btc:1m:volume',\n 'markets:crypto:btc:raw:close',\n 'markets:crypto:btc:raw:high',\n 'markets:crypto:btc:raw:low',\n 'markets:crypto:btc:raw:open',\n 'markets:crypto:btc:raw:volume',\n 'markets:crypto:eth:1d:close',\n 'markets:crypto:eth:1d:high',\n 'markets:crypto:eth:1d:low',\n 'markets:crypto:eth:1d:open',\n 'markets:crypto:eth:1d:volume',\n 'markets:crypto:eth:1h:close',\n 'markets:crypto:eth:1h:high',\n 'markets:crypto:eth:1h:low',\n 'markets:crypto:eth:1h:open',\n 'markets:crypto:eth:1h:volume',\n 'markets:crypto:eth:1m:close',\n 'markets:crypto:eth:1m:high',\n 'markets:crypto:eth:1m:low',\n 'markets:crypto:eth:1m:open',\n 'markets:crypto:eth:1m:volume',\n 'markets:crypto:eth:raw:close',\n 'markets:crypto:eth:raw:high',\n 'markets:crypto:eth:raw:low',\n 'markets:crypto:eth:raw:open',\n 'markets:crypto:eth:raw:volume',\n 'markets:irx:usd:1d:close',\n 'markets:irx:usd:1d:high',\n 'markets:irx:usd:1d:low',\n 'markets:irx:usd:1d:open',\n 'markets:irx:usd:1d:volume',\n 'markets:irx:usd:1h:close',\n 'markets:irx:usd:1h:high',\n 'markets:irx:usd:1h:low',\n 'markets:irx:usd:1h:open',\n 'markets:irx:usd:1h:volume',\n 'markets:irx:usd:1m:close',\n 'markets:irx:usd:1m:high',\n 'markets:irx:usd:1m:low',\n 'markets:irx:usd:1m:open',\n 'markets:irx:usd:1m:volume',\n 'markets:irx:usd:raw:close',\n 'markets:irx:usd:raw:high',\n 'markets:irx:usd:raw:low',\n 'markets:irx:usd:raw:open',\n 'markets:irx:usd:raw:volume']\n\n\nYou can inspect the info of each key by running the stats command as shown in the next cell.\n\nNote that each key have lablels properly filled with respective data(c1, c2, ...), so you can take advantage of redis multi-timeseries commands like TS.MRANGE\n\n\nmd.stats('crypto', 'btc', 'raw', 'close').__dict__\n\n{'rules': [[b'markets:crypto:btc:1m:close', 60000, b'LAST'],\n  [b'markets:crypto:btc:1h:close', 3600000, b'LAST'],\n  [b'markets:crypto:btc:1d:close', 86400000, b'LAST']],\n 'source_key': None,\n 'chunk_count': 4,\n 'memory_usage': 17013,\n 'total_samples': 5761,\n 'labels': {'tl': 'markets',\n  'c1': 'crypto',\n  'c2': 'btc',\n  'line': 'close',\n  'timeframe': 'raw'},\n 'retention_msecs': 345600000,\n 'lastTimeStamp': 1583020740000,\n 'first_time_stamp': 1582675140000,\n 'chunk_size': 4096,\n 'duplicate_policy': 'last'}"
  }
]